{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8fa7f3d-d25e-48dc-a8ad-d7361cc9f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://chunkerbert/v2/docker.txt...\n",
      "\\ [1 files][723.2 MiB/723.2 MiB]                                                \n",
      "Operation completed over 1 objects/723.2 MiB.                                    \n",
      "Copying gs://chunkerbert/v2/windows.txt...\n",
      "| [1 files][877.7 MiB/877.7 MiB]                                                \n",
      "Operation completed over 1 objects/877.7 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://chunkerbert/v2/docker.txt .\n",
    "!gsutil cp gs://chunkerbert/v2/windows.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bded82ec-3408-4b47-9a58-def6cdf3aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://chunkerbert/v2/bert-wordpiecev2-vocab.txt...\n",
      "/ [1 files][  1.2 MiB/  1.2 MiB]                                                \n",
      "Operation completed over 1 objects/1.2 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://chunkerbert/v2/bert-wordpiecev3-vocab.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a56603a-fab0-4ad3-88d5-77b9c105cf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 1.6G Aug 19 13:16 dataset.txt\n"
     ]
    }
   ],
   "source": [
    "!rm dataset.txt\n",
    "!cat docker.txt >> dataset.txt\n",
    "!cat windows.txt >> dataset.txt\n",
    "!ls -lah dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d8ed983-a5bd-44a3-a5c7-67c13ad1f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'bert' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentencepiece \n",
    "!pip install -q nltk\n",
    "!git clone https://github.com/google-research/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7116b5c-b5cb-472b-a173-31045a99c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "import random\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "\n",
    "from glob import glob\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "sys.path.append(\"bert\")\n",
    "\n",
    "from bert import modeling, optimization, tokenization\n",
    "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
    "\n",
    "  \n",
    "# configure logging\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "log.handlers = [sh]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c629031e-fda5-428f-b13b-e5113b36e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tokenizer = nltk.RegexpTokenizer(\"\\w+\")\n",
    "\n",
    "def normalize_text(text):\n",
    "  # lowercase text\n",
    "  text = str(text).lower()\n",
    "  # remove non-UTF\n",
    "  text = text.encode(\"utf-8\", \"ignore\").decode()\n",
    "  # remove punktuation symbols\n",
    "  text = \" \".join(regex_tokenizer.tokenize(text))\n",
    "  return text\n",
    "\n",
    "def count_lines(filename):\n",
    "  count = 0\n",
    "  with open(filename) as fi:\n",
    "    for line in fi:\n",
    "      count += 1\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17baf24e-80ba-452f-9246-1061d914694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726164/726164 [==============================] - 25s 35us/step\n"
     ]
    }
   ],
   "source": [
    "RAW_DATA_FPATH = \"dataset.txt\" #@param {type: \"string\"}\n",
    "PRC_DATA_FPATH = \"proc_dataset.txt\" #@param {type: \"string\"}\n",
    "\n",
    "# apply normalization to the dataset\n",
    "# this will take a minute or two\n",
    "\n",
    "total_lines = count_lines(RAW_DATA_FPATH)\n",
    "bar = Progbar(total_lines)\n",
    "\n",
    "with open(RAW_DATA_FPATH,encoding=\"utf-8\") as fi:\n",
    "  with open(PRC_DATA_FPATH, \"w\",encoding=\"utf-8\") as fo:\n",
    "    for l in fi:\n",
    "      fo.write(normalize_text(l)+\"\\n\")\n",
    "      bar.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08062ec9-02dc-4fed-8265-d02e91026aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_FNAME = \"bert-wordpiecev3-vocab.txt\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726f05d3-cd66-420a-818a-7f2cb7723349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shard_0000  shard_0005\tshard_0010  shard_0015\tshard_0020  shard_0025\n",
      "shard_0001  shard_0006\tshard_0011  shard_0016\tshard_0021  shard_0026\n",
      "shard_0002  shard_0007\tshard_0012  shard_0017\tshard_0022  shard_0027\n",
      "shard_0003  shard_0008\tshard_0013  shard_0018\tshard_0023  shard_0028\n",
      "shard_0004  shard_0009\tshard_0014  shard_0019\tshard_0024\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./shards\n",
    "!mkdir ./shards\n",
    "!split -a 4 -l 25600 -d $PRC_DATA_FPATH ./shards/shard_\n",
    "!ls ./shards/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83ec316-3943-48e6-ae26-e3a0051f7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 512 #@param {type:\"integer\"}\n",
    "MASKED_LM_PROB = 0.15 #@param\n",
    "MAX_PREDICTIONS = 77 #@param {type:\"integer\"}\n",
    "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
    "PROCESSES = 6 #@param {type:\"integer\"}\n",
    "PRETRAINING_DIR = \"pretraining_data_docker4\" #@param {type:\"string\"}\n",
    "BUCKET_NAME = \"chunkbert_training\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "985a2897-9e62-40dc-8f4b-dfa1d81d2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "XARGS_CMD = (\"ls ./shards/ | \"\n",
    "             \"xargs -n 1 -P {} -I{} \"\n",
    "             \"python3 bert/create_pretraining_data.py \"\n",
    "             \"--input_file=./shards/{} \"\n",
    "             \"--output_file={}/{}.tfrecord \"\n",
    "             \"--vocab_file={} \"\n",
    "             \"--do_lower_case={} \"\n",
    "             \"--max_predictions_per_seq={} \"\n",
    "             \"--max_seq_length={} \"\n",
    "             \"--masked_lm_prob={} \"\n",
    "             \"--random_seed=34 \"\n",
    "             \"--dupe_factor=5\")\n",
    "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n",
    "                             VOC_FNAME, DO_LOWER_CASE, \n",
    "                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26ed625-c21f-4e56-b536-d8515e565786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 21:25:57,063 :  From /tmp/ipykernel_1485/312981126.py:1: The name tf.gfile.MkDir is deprecated. Please use tf.io.gfile.mkdir instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0811 21:25:58.990888 140667984258880 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0811 21:25:58.991050 140667984258880 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0811 21:25:58.991186 140667984258880 module_wrapper.py:139] From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0811 21:25:59.000122 139675671770944 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0811 21:25:59.000275 139675671770944 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0811 21:25:59.000408 139675671770944 module_wrapper.py:139] From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0811 21:25:59.020481 140160088934208 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0811 21:25:59.020630 140160088934208 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0811 21:25:59.020764 140160088934208 module_wrapper.py:139] From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0811 21:25:59.029634 140676727760704 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0811 21:25:59.029816 140676727760704 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0811 21:25:59.030004 140676727760704 module_wrapper.py:139] From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0811 21:25:59.033542 140398907586368 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0811 21:25:59.033687 140398907586368 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0811 21:25:59.033819 140398907586368 module_wrapper.py:139] From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0811 21:25:59.053500 139905170024256 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0811 21:25:59.053656 139905170024256 module_wrapper.py:139] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0811 21:25:59.053792 139905170024256 module_wrapper.py:139] From /home/jupyter/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0811 21:25:59.276041 140667984258880 module_wrapper.py:139] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0811 21:25:59.277916 140667984258880 module_wrapper.py:139] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I0811 21:25:59.278084 140667984258880 create_pretraining_data.py:446] *** Reading from input files ***\n",
      "INFO:tensorflow:  ./shards/shard_0000\n",
      "I0811 21:25:59.278144 140667984258880 create_pretraining_data.py:448]   ./shards/shard_0000\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0811 21:25:59.284713 139675671770944 module_wrapper.py:139] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0811 21:25:59.286421 139675671770944 module_wrapper.py:139] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I0811 21:25:59.286619 139675671770944 create_pretraining_data.py:446] *** Reading from input files ***\n",
      "INFO:tensorflow:  ./shards/shard_0004\n",
      "I0811 21:25:59.286696 139675671770944 create_pretraining_data.py:448]   ./shards/shard_0004\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0811 21:25:59.302140 140160088934208 module_wrapper.py:139] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0811 21:25:59.303907 140160088934208 module_wrapper.py:139] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I0811 21:25:59.304086 140160088934208 create_pretraining_data.py:446] *** Reading from input files ***\n",
      "INFO:tensorflow:  ./shards/shard_0003\n",
      "I0811 21:25:59.304154 140160088934208 create_pretraining_data.py:448]   ./shards/shard_0003\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0811 21:25:59.313959 140676727760704 module_wrapper.py:139] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0811 21:25:59.315665 140676727760704 module_wrapper.py:139] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I0811 21:25:59.315836 140676727760704 create_pretraining_data.py:446] *** Reading from input files ***\n",
      "INFO:tensorflow:  ./shards/shard_0001\n",
      "I0811 21:25:59.315914 140676727760704 create_pretraining_data.py:448]   ./shards/shard_0001\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0811 21:25:59.317329 140398907586368 module_wrapper.py:139] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0811 21:25:59.318901 140398907586368 module_wrapper.py:139] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I0811 21:25:59.319064 140398907586368 create_pretraining_data.py:446] *** Reading from input files ***\n",
      "INFO:tensorflow:  ./shards/shard_0005\n",
      "I0811 21:25:59.319126 140398907586368 create_pretraining_data.py:448]   ./shards/shard_0005\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0811 21:25:59.333972 139905170024256 module_wrapper.py:139] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0811 21:25:59.335623 139905170024256 module_wrapper.py:139] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I0811 21:25:59.335783 139905170024256 create_pretraining_data.py:446] *** Reading from input files ***\n",
      "INFO:tensorflow:  ./shards/shard_0002\n",
      "I0811 21:25:59.335845 139905170024256 create_pretraining_data.py:448]   ./shards/shard_0002\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"bert/create_pretraining_data.py\", line 469, in <module>\n",
      "  File \"bert/create_pretraining_data.py\", line 469, in <module>\n",
      "  File \"bert/create_pretraining_data.py\", line 469, in <module>\n",
      "  File \"bert/create_pretraining_data.py\", line 469, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"bert/create_pretraining_data.py\", line 469, in <module>\n",
      "  File \"bert/create_pretraining_data.py\", line 469, in <module>\n",
      "    tf.app.run()\n",
      "    tf.app.run()\n",
      "    tf.app.run()\n",
      "    tf.app.run()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    tf.app.run()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    tf.app.run()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n"
     ]
    }
   ],
   "source": [
    "tf.gfile.MkDir(PRETRAINING_DIR)\n",
    "!$XARGS_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf01c6-ed85-4dfb-9d35-6c13edd3e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r $PRETRAINING_DIR gs://$BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf-gpu.1-15.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m94"
  },
  "kernelspec": {
   "display_name": "Custom [tf-gpu.1-15] (Local)",
   "language": "python",
   "name": "local-us-central1-docker.pkg.dev_lemmingsinthewind_workbench_tf-gpu.1-15_sha256_572a87b2ba89b08714325c28261c6917f5623fd6e31246cd07daa7200f9753e3__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
