{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67249f2-d6c9-42da-bfd3-9d390549eb07",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749fd2aa-2849-4401-9fa3-a93af02aa885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert'...\n",
      "remote: Enumerating objects: 340, done.\u001b[K\n",
      "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
      "Receiving objects: 100% (340/340), 328.28 KiB | 4.50 MiB/s, done.\n",
      "Resolving deltas: 100% (182/182), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/google-research/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be9e11a-d604-4650-9cf5-6eba88f4d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import tpu_v1\n",
    "#auth_file=\"lemmingsinthewind-6f1cdbe0f4b8.json\"\n",
    "zone=\"us-central1-a\"\n",
    "tpuname=\"projects/lemmingsinthewind/locations/{zone}/nodes/bertme\".format(zone=zone)\n",
    "\n",
    "\n",
    "\n",
    "client = tpu_v1.TpuClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bf668a-17cc-4007-8be8-39aa9c85903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/lemmingsinthewind/locations/us-central1-a/nodes/bertme\"\n",
      "accelerator_type: \"v3-8\"\n",
      "ip_address: \"10.110.1.2\"\n",
      "state: READY\n",
      "tensorflow_version: \"1.15.5\"\n",
      "network: \"projects/1053790116294/global/networks/default\"\n",
      "cidr_block: \"10.110.1.0/29\"\n",
      "port: \"8470\"\n",
      "service_account: \"service-501306953789@cloud-tpu.iam.gserviceaccount.com\"\n",
      "create_time {\n",
      "  seconds: 1660455199\n",
      "  nanos: 286475120\n",
      "}\n",
      "scheduling_config {\n",
      "}\n",
      "network_endpoints {\n",
      "  ip_address: \"10.110.1.2\"\n",
      "  port: 8470\n",
      "}\n",
      "health: HEALTHY\n",
      "use_service_networking: true\n",
      "api_version: V1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    request = tpu_v1.GetNodeRequest(\n",
    "        name=tpuname,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    response = client.get_node(request=request)\n",
    "except:\n",
    "    response=None\n",
    "\n",
    "# Handle the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c047bba-c35b-4034-9d32-30b2f29743a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response==None:\n",
    "    # Initialize request argument(s)\n",
    "    sc = tpu_v1.SchedulingConfig()\n",
    "    sc.preemptible=False\n",
    "    node = tpu_v1.Node()\n",
    "    node.accelerator_type = \"v3-8\"\n",
    "    node.tensorflow_version = \"1.15.5\"\n",
    "    node.scheduling_config = sc\n",
    "    node.use_service_networking=True\n",
    "    node.network=\"projects/hazel-goal-319318/global/networks/default\"\n",
    "    request = tpu_v1.CreateNodeRequest(\n",
    "            parent=\"projects/lemmingsinthewind/locations/us-central1-a\",\n",
    "         node_id='bertme',\n",
    "        node=node\n",
    "    )\n",
    "    # Make the request\n",
    "    operation = client.create_node(request=request)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "\n",
    "    response = operation.result()\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f9e6a2-f7b0-47c7-a3e6-ab6e1541526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 15:44:39.225410: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 15:44:41,638 :  Using TPU runtime\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import random\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "\n",
    "from glob import glob\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "sys.path.append(\"bert\")\n",
    "\n",
    "from bert import modeling, optimization, tokenization\n",
    "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
    "\n",
    "  \n",
    "# configure logging\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
    "sh = logging.StreamHandler()\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "log.handlers = [sh]\n",
    "\n",
    "log.info(\"Using TPU runtime\")\n",
    "USE_TPU = True\n",
    "TPU_ADDRESS = 'grpc://'+response.ip_address+':'+response.port\n",
    "with tf.Session(TPU_ADDRESS) as session:\n",
    "    log.info('TPU address is ' + TPU_ADDRESS)\n",
    "    # Upload credentials to TPU.\n",
    "    print(session)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e97c1f3-5a74-4d7a-ae1d-776c8ca1adc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.server_lib.ClusterSpec at 0x7f9b065ef2d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpur =tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "    tpu='bertme', zone=zone, project='lemmingsinthewind', job_name='worker'\n",
    ")\n",
    "tpur.cluster_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1130e668-019a-45a4-af93-63b539a58cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 15:44:49,354 :  From /tmp/ipykernel_1/751807384.py:6: The name tf.gfile.MkDir is deprecated. Please use tf.io.gfile.mkdir instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"chunkbert_training\" #@param {type:\"string\"}\n",
    "MODEL_DIR = \"bert_model3\" #@param {type:\"string\"}\n",
    "VOC_FNAME= 'bert-wordpiecev3-vocab.txt'\n",
    "PRETRAINING_DIR = \"pretraining_data_docker4\" #@param {type:\"string\"}\n",
    "\n",
    "tf.gfile.MkDir(MODEL_DIR)\n",
    "\n",
    "if not BUCKET_NAME:\n",
    "  log.warning(\"WARNING: BUCKET_NAME is not set. \"\n",
    "              \"You will not be able to train the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff9da6d-a25f-47dc-8f08-84aec55c33cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_config = {\n",
    "  \"attention_probs_dropout_prob\": 0.1, \n",
    "  \"directionality\": \"bidi\", \n",
    "  \"hidden_act\": \"gelu\", \n",
    "  \"hidden_dropout_prob\": 0.1, \n",
    "  \"hidden_size\": 768, \n",
    "  \"initializer_range\": 0.02, \n",
    "  \"intermediate_size\": 3072, \n",
    "  \"max_position_embeddings\": 512, \n",
    "  \"num_attention_heads\": 12, \n",
    "  \"num_hidden_layers\": 24, \n",
    "  \"pooler_fc_size\": 768, \n",
    "  \"pooler_num_attention_heads\": 12, \n",
    "  \"pooler_num_fc_layers\": 3, \n",
    "  \"pooler_size_per_head\": 128, \n",
    "  \"pooler_type\": \"first_token_transform\", \n",
    "  \"type_vocab_size\": 2, \n",
    "  \"vocab_size\": 128000\n",
    "}\n",
    "\n",
    "with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
    "  json.dump(bert_base_config, fo, indent=2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947ad5e1-12ef-4f6c-9a3f-af3ab3881c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://bert_model3/bert_config.json [Content-Type=application/json]...\n",
      "Copying file://bert_model3/.ipynb_checkpoints/bert_config-checkpoint.json [Content-Type=application/json]...\n",
      "/ [2/2 files][   1008 B/   1008 B] 100% Done                                    \n",
      "Operation completed over 2 objects/1008.0 B.                                     \n"
     ]
    }
   ],
   "source": [
    "if BUCKET_NAME:\n",
    "  !gsutil -m cp -r $MODEL_DIR gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fe43a2-f2b4-40ee-af33-2c1fbd9fcfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 15:45:38,182 :  From /home/jupyter/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "2022-08-23 15:45:38,363 :  From /tmp/ipykernel_1/2499664015.py:28: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "2022-08-23 15:45:38,420 :  Using checkpoint: None\n",
      "2022-08-23 15:45:38,422 :  Using 29 data shards\n"
     ]
    }
   ],
   "source": [
    "# Input data pipeline config\n",
    "TRAIN_BATCH_SIZE = 256 #@param {type:\"integer\"}\n",
    "MAX_PREDICTIONS = 77 #@param {type:\"integer\"}\n",
    "MAX_SEQ_LENGTH = 512 #@param {type:\"integer\"}\n",
    "MASKED_LM_PROB = 0.15 #@param\n",
    "\n",
    "# Training procedure config\n",
    "EVAL_BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAIN_STEPS = 1000000 #@param {type:\"integer\"}\n",
    "SAVE_CHECKPOINTS_STEPS = 2500 #@param {type:\"integer\"}\n",
    "NUM_TPU_CORES = 8\n",
    "\n",
    "if BUCKET_NAME:\n",
    "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
    "else:\n",
    "  BUCKET_PATH = \".\"\n",
    "\n",
    "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
    "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
    "\n",
    "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n",
    "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
    "\n",
    "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
    "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
    "\n",
    "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
    "log.info(\"Using {} data shards\".format(len(input_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4ded73-cab2-4381-a3d6-23f2bbf53886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 15:46:20,434 :  \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2022-08-23 15:46:26,926 :  Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9b06618200>) includes params argument, but params are not passed to Estimator.\n",
      "2022-08-23 15:46:26,928 :  Using config: {'_model_dir': 'gs://chunkbert_training/bert_model3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 2500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "cluster_def {\n",
      "  job {\n",
      "    name: \"worker\"\n",
      "    tasks {\n",
      "      key: 0\n",
      "      value: \"10.110.1.2:8470\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9b03e9c210>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.110.1.2:8470', '_evaluation_master': 'grpc://10.110.1.2:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2500, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f9bd4d530d0>}\n",
      "2022-08-23 15:46:26,930 :  _TPUContext: eval_on_tpu True\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "      bert_config=bert_config,\n",
    "      init_checkpoint=INIT_CHECKPOINT,\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=TRAIN_STEPS,\n",
    "      num_warmup_steps=10000,\n",
    "      use_tpu=True,\n",
    "      use_one_hot_embeddings=True)\n",
    "\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpur,\n",
    "    model_dir=BERT_GCS_DIR,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
    "        num_shards=NUM_TPU_CORES,\n",
    "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=USE_TPU,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE)\n",
    "  \n",
    "train_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
    "        is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04962c9e-43c2-4bf8-b10a-7edafc685c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 15:46:27,033 :  Querying Tensorflow master (grpc://10.110.1.2:8470) for TPU system metadata.\n",
      "2022-08-23 15:46:27.246282: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
      "2022-08-23 15:46:27,284 :  Found TPU system:\n",
      "2022-08-23 15:46:27,285 :  *** Num TPU Cores: 8\n",
      "2022-08-23 15:46:27,287 :  *** Num TPU Workers: 1\n",
      "2022-08-23 15:46:27,289 :  *** Num TPU Cores Per Worker: 8\n",
      "2022-08-23 15:46:27,291 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7448239727632855550)\n",
      "2022-08-23 15:46:27,293 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17791925804359808359)\n",
      "2022-08-23 15:46:27,295 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2447259900016301126)\n",
      "2022-08-23 15:46:27,296 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10115237712411442931)\n",
      "2022-08-23 15:46:27,297 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 3925813311766719496)\n",
      "2022-08-23 15:46:27,298 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11442020869384245207)\n",
      "2022-08-23 15:46:27,299 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10285825313483776776)\n",
      "2022-08-23 15:46:27,300 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8684164327041838688)\n",
      "2022-08-23 15:46:27,302 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8836025281133991006)\n",
      "2022-08-23 15:46:27,303 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 1988884833342937678)\n",
      "2022-08-23 15:46:27,304 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4923707789991326070)\n",
      "2022-08-23 15:46:27,355 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "2022-08-23 15:46:27,357 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "2022-08-23 15:46:27,380 :  Calling model_fn.\n",
      "2022-08-23 15:46:27,382 :  From /home/jupyter/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "2022-08-23 15:46:27,395 :  From /home/jupyter/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "2022-08-23 15:46:27,396 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "2022-08-23 15:46:27,477 :  From /home/jupyter/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "2022-08-23 15:46:27,478 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "2022-08-23 15:46:27,615 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "2022-08-23 15:46:27,914 :  From /home/jupyter/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-08-23 15:46:27,984 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:27,989 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:27,995 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:28,001 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:28,006 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:28,011 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:28,018 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:28,023 :  Found small feature: next_sentence_labels [32, 1]\n",
      "2022-08-23 15:46:28.077145: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-23 15:46:28.089403: E tensorflow/stream_executor/cuda/cuda_driver.cc:322] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-23 15:46:28.089515: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (52a502cb5a99): /proc/driver/nvidia/version does not exist\n",
      "2022-08-23 15:46:28,116 :  From /home/jupyter/bert/run_pretraining.py:117: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "2022-08-23 15:46:28,118 :  *** Features ***\n",
      "2022-08-23 15:46:28,119 :    name = input_ids, shape = (32, 512)\n",
      "2022-08-23 15:46:28,120 :    name = input_mask, shape = (32, 512)\n",
      "2022-08-23 15:46:28,122 :    name = masked_lm_ids, shape = (32, 77)\n",
      "2022-08-23 15:46:28,122 :    name = masked_lm_positions, shape = (32, 77)\n",
      "2022-08-23 15:46:28,123 :    name = masked_lm_weights, shape = (32, 77)\n",
      "2022-08-23 15:46:28,124 :    name = next_sentence_labels, shape = (32, 1)\n",
      "2022-08-23 15:46:28,128 :    name = segment_ids, shape = (32, 512)\n",
      "2022-08-23 15:46:28,129 :  From bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "2022-08-23 15:46:28,138 :  From bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "2022-08-23 15:46:28,191 :  From bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "2022-08-23 15:46:28,299 :  From bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2022-08-23 15:46:28,340 :  From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "2022-08-23 15:46:28,343 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "2022-08-23 15:46:37,118 :  From /home/jupyter/bert/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "2022-08-23 15:46:37,119 :  **** Trainable Variables ****\n",
      "2022-08-23 15:46:37,121 :    name = bert/embeddings/word_embeddings:0, shape = (128000, 768)\n",
      "2022-08-23 15:46:37,123 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
      "2022-08-23 15:46:37,124 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
      "2022-08-23 15:46:37,126 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,129 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,131 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,133 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,136 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,137 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,138 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,140 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,141 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,143 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,144 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,147 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,151 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,152 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,153 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,154 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,156 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,157 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,159 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,160 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,161 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,163 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,164 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,166 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,167 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,168 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,170 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,174 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,177 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,180 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,182 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,182 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,183 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,185 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,190 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,196 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,197 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,198 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,199 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,201 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,202 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,203 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,209 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,211 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,212 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,213 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,214 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,215 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,219 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,221 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,223 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,224 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,226 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,227 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,230 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,230 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,232 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,233 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,235 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,236 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,238 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,240 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,241 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,243 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,244 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,246 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,248 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,249 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,250 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,252 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,253 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,254 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,256 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,257 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,260 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,261 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,263 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,264 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,266 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,267 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,268 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,269 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,271 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,272 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,273 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,274 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,275 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,276 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,277 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,279 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,283 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,285 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,287 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,288 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,289 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,291 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,292 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,293 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,294 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,295 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,297 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,298 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,299 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,301 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,302 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,303 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,304 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,306 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,307 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,309 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,310 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,311 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,313 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,315 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,317 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,318 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,320 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,322 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,324 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,325 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,327 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,329 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,330 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,331 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,332 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,333 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,334 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,335 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,336 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,338 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,339 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,340 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,341 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,343 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,344 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,345 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,346 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,347 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,348 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,350 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,352 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,353 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,354 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,355 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,356 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,358 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,359 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,360 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,361 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,362 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,363 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,365 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,366 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,367 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,367 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,369 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,370 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,371 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,373 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,374 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,376 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,377 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,379 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,380 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,381 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,383 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,384 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,385 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,388 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,391 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,393 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,395 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,397 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,399 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,403 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,406 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,407 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,408 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,409 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,410 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,411 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,414 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,417 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,419 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,421 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,422 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,423 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,424 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,427 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,428 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,431 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,433 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,434 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,436 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,437 :    name = bert/encoder/layer_12/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,438 :    name = bert/encoder/layer_12/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,439 :    name = bert/encoder/layer_12/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,440 :    name = bert/encoder/layer_12/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,442 :    name = bert/encoder/layer_12/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,443 :    name = bert/encoder/layer_12/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,447 :    name = bert/encoder/layer_12/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,448 :    name = bert/encoder/layer_12/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,450 :    name = bert/encoder/layer_12/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,451 :    name = bert/encoder/layer_12/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,453 :    name = bert/encoder/layer_12/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,454 :    name = bert/encoder/layer_12/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,455 :    name = bert/encoder/layer_12/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,458 :    name = bert/encoder/layer_12/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,459 :    name = bert/encoder/layer_12/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,461 :    name = bert/encoder/layer_12/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,462 :    name = bert/encoder/layer_13/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,464 :    name = bert/encoder/layer_13/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,466 :    name = bert/encoder/layer_13/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,468 :    name = bert/encoder/layer_13/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,469 :    name = bert/encoder/layer_13/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,470 :    name = bert/encoder/layer_13/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,472 :    name = bert/encoder/layer_13/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,473 :    name = bert/encoder/layer_13/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,476 :    name = bert/encoder/layer_13/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,477 :    name = bert/encoder/layer_13/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,478 :    name = bert/encoder/layer_13/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,482 :    name = bert/encoder/layer_13/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,483 :    name = bert/encoder/layer_13/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,485 :    name = bert/encoder/layer_13/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,487 :    name = bert/encoder/layer_13/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,489 :    name = bert/encoder/layer_13/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,490 :    name = bert/encoder/layer_14/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,492 :    name = bert/encoder/layer_14/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,493 :    name = bert/encoder/layer_14/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,495 :    name = bert/encoder/layer_14/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,496 :    name = bert/encoder/layer_14/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,497 :    name = bert/encoder/layer_14/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,498 :    name = bert/encoder/layer_14/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,500 :    name = bert/encoder/layer_14/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,502 :    name = bert/encoder/layer_14/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,503 :    name = bert/encoder/layer_14/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,505 :    name = bert/encoder/layer_14/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,508 :    name = bert/encoder/layer_14/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,509 :    name = bert/encoder/layer_14/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,510 :    name = bert/encoder/layer_14/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,512 :    name = bert/encoder/layer_14/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,514 :    name = bert/encoder/layer_14/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,515 :    name = bert/encoder/layer_15/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,516 :    name = bert/encoder/layer_15/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,517 :    name = bert/encoder/layer_15/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,518 :    name = bert/encoder/layer_15/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,519 :    name = bert/encoder/layer_15/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,520 :    name = bert/encoder/layer_15/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,523 :    name = bert/encoder/layer_15/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,524 :    name = bert/encoder/layer_15/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,526 :    name = bert/encoder/layer_15/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,527 :    name = bert/encoder/layer_15/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,529 :    name = bert/encoder/layer_15/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,530 :    name = bert/encoder/layer_15/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,531 :    name = bert/encoder/layer_15/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,532 :    name = bert/encoder/layer_15/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,533 :    name = bert/encoder/layer_15/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,534 :    name = bert/encoder/layer_15/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,535 :    name = bert/encoder/layer_16/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,536 :    name = bert/encoder/layer_16/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,538 :    name = bert/encoder/layer_16/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,539 :    name = bert/encoder/layer_16/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,541 :    name = bert/encoder/layer_16/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,542 :    name = bert/encoder/layer_16/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,543 :    name = bert/encoder/layer_16/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,544 :    name = bert/encoder/layer_16/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,545 :    name = bert/encoder/layer_16/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,547 :    name = bert/encoder/layer_16/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,550 :    name = bert/encoder/layer_16/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,556 :    name = bert/encoder/layer_16/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,557 :    name = bert/encoder/layer_16/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,558 :    name = bert/encoder/layer_16/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,559 :    name = bert/encoder/layer_16/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,563 :    name = bert/encoder/layer_16/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,565 :    name = bert/encoder/layer_17/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,568 :    name = bert/encoder/layer_17/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,571 :    name = bert/encoder/layer_17/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,572 :    name = bert/encoder/layer_17/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,574 :    name = bert/encoder/layer_17/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,575 :    name = bert/encoder/layer_17/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,576 :    name = bert/encoder/layer_17/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,578 :    name = bert/encoder/layer_17/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,579 :    name = bert/encoder/layer_17/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,580 :    name = bert/encoder/layer_17/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,582 :    name = bert/encoder/layer_17/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,583 :    name = bert/encoder/layer_17/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,584 :    name = bert/encoder/layer_17/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,586 :    name = bert/encoder/layer_17/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,587 :    name = bert/encoder/layer_17/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,587 :    name = bert/encoder/layer_17/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,588 :    name = bert/encoder/layer_18/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,589 :    name = bert/encoder/layer_18/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,591 :    name = bert/encoder/layer_18/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,593 :    name = bert/encoder/layer_18/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,594 :    name = bert/encoder/layer_18/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,596 :    name = bert/encoder/layer_18/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,597 :    name = bert/encoder/layer_18/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,598 :    name = bert/encoder/layer_18/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,601 :    name = bert/encoder/layer_18/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,602 :    name = bert/encoder/layer_18/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,603 :    name = bert/encoder/layer_18/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,604 :    name = bert/encoder/layer_18/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,605 :    name = bert/encoder/layer_18/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,606 :    name = bert/encoder/layer_18/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,608 :    name = bert/encoder/layer_18/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,609 :    name = bert/encoder/layer_18/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,610 :    name = bert/encoder/layer_19/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,612 :    name = bert/encoder/layer_19/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,613 :    name = bert/encoder/layer_19/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,614 :    name = bert/encoder/layer_19/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,615 :    name = bert/encoder/layer_19/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,617 :    name = bert/encoder/layer_19/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,618 :    name = bert/encoder/layer_19/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,619 :    name = bert/encoder/layer_19/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,620 :    name = bert/encoder/layer_19/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,621 :    name = bert/encoder/layer_19/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,622 :    name = bert/encoder/layer_19/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,624 :    name = bert/encoder/layer_19/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,625 :    name = bert/encoder/layer_19/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,626 :    name = bert/encoder/layer_19/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,627 :    name = bert/encoder/layer_19/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,628 :    name = bert/encoder/layer_19/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,629 :    name = bert/encoder/layer_20/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,631 :    name = bert/encoder/layer_20/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,632 :    name = bert/encoder/layer_20/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,634 :    name = bert/encoder/layer_20/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,635 :    name = bert/encoder/layer_20/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,636 :    name = bert/encoder/layer_20/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,637 :    name = bert/encoder/layer_20/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,639 :    name = bert/encoder/layer_20/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,641 :    name = bert/encoder/layer_20/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,642 :    name = bert/encoder/layer_20/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,643 :    name = bert/encoder/layer_20/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,644 :    name = bert/encoder/layer_20/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,646 :    name = bert/encoder/layer_20/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,647 :    name = bert/encoder/layer_20/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,648 :    name = bert/encoder/layer_20/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,649 :    name = bert/encoder/layer_20/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,652 :    name = bert/encoder/layer_21/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,660 :    name = bert/encoder/layer_21/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,662 :    name = bert/encoder/layer_21/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,663 :    name = bert/encoder/layer_21/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,665 :    name = bert/encoder/layer_21/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,666 :    name = bert/encoder/layer_21/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,667 :    name = bert/encoder/layer_21/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,668 :    name = bert/encoder/layer_21/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,670 :    name = bert/encoder/layer_21/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,672 :    name = bert/encoder/layer_21/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,673 :    name = bert/encoder/layer_21/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,674 :    name = bert/encoder/layer_21/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,675 :    name = bert/encoder/layer_21/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,676 :    name = bert/encoder/layer_21/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,678 :    name = bert/encoder/layer_21/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,679 :    name = bert/encoder/layer_21/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,683 :    name = bert/encoder/layer_22/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,684 :    name = bert/encoder/layer_22/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,686 :    name = bert/encoder/layer_22/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,689 :    name = bert/encoder/layer_22/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,691 :    name = bert/encoder/layer_22/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,693 :    name = bert/encoder/layer_22/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,694 :    name = bert/encoder/layer_22/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,695 :    name = bert/encoder/layer_22/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,696 :    name = bert/encoder/layer_22/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,697 :    name = bert/encoder/layer_22/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,698 :    name = bert/encoder/layer_22/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,699 :    name = bert/encoder/layer_22/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,701 :    name = bert/encoder/layer_22/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,702 :    name = bert/encoder/layer_22/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,704 :    name = bert/encoder/layer_22/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,706 :    name = bert/encoder/layer_22/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,707 :    name = bert/encoder/layer_23/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,709 :    name = bert/encoder/layer_23/attention/self/query/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,710 :    name = bert/encoder/layer_23/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,711 :    name = bert/encoder/layer_23/attention/self/key/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,712 :    name = bert/encoder/layer_23/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,714 :    name = bert/encoder/layer_23/attention/self/value/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,715 :    name = bert/encoder/layer_23/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,717 :    name = bert/encoder/layer_23/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,718 :    name = bert/encoder/layer_23/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,720 :    name = bert/encoder/layer_23/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,721 :    name = bert/encoder/layer_23/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-08-23 15:46:37,723 :    name = bert/encoder/layer_23/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-08-23 15:46:37,724 :    name = bert/encoder/layer_23/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-08-23 15:46:37,725 :    name = bert/encoder/layer_23/output/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,727 :    name = bert/encoder/layer_23/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,728 :    name = bert/encoder/layer_23/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,729 :    name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,730 :    name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,731 :    name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
      "2022-08-23 15:46:37,733 :    name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
      "2022-08-23 15:46:37,735 :    name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
      "2022-08-23 15:46:37,736 :    name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-08-23 15:46:37,737 :    name = cls/predictions/output_bias:0, shape = (128000,)\n",
      "2022-08-23 15:46:37,738 :    name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
      "2022-08-23 15:46:37,739 :    name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
      "2022-08-23 15:46:37,741 :  From bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "2022-08-23 15:46:37,760 :  From bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "2022-08-23 15:46:38,790 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2022-08-23 15:47:08,679 :  Create CheckpointSaverHook.\n",
      "2022-08-23 15:47:09,653 :  Done calling model_fn.\n",
      "2022-08-23 15:47:15,032 :  TPU job name worker\n",
      "2022-08-23 15:47:18,780 :  Graph was finalized.\n",
      "2022-08-23 15:47:39,586 :  Running local_init_op.\n",
      "2022-08-23 15:47:40,566 :  Done running local_init_op.\n",
      "2022-08-23 15:48:02,956 :  Saving checkpoints for 0 into gs://chunkbert_training/bert_model3/model.ckpt.\n",
      "2022-08-23 15:48:28,528 :  From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "2022-08-23 15:48:30,615 :  Initialized dataset iterators in 1 seconds\n",
      "2022-08-23 15:48:30,617 :  Installing graceful shutdown hook.\n",
      "2022-08-23 15:48:30.620111: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
      "2022-08-23 15:48:30,625 :  Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
      "2022-08-23 15:48:30,631 :  Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
      "\n",
      "2022-08-23 15:48:30,639 :  Init TPU system\n",
      "2022-08-23 15:48:33,714 :  Initialized TPU in 3 seconds\n",
      "2022-08-23 15:48:33,717 :  Starting infeed thread controller.\n",
      "2022-08-23 15:48:33,720 :  Starting outfeed thread controller.\n",
      "2022-08-23 15:48:34,716 :  Enqueue next (2500) batch(es) of data to infeed.\n",
      "2022-08-23 15:48:34,718 :  Dequeue next (2500) batch(es) of data from outfeed.\n"
     ]
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45e562-88ce-427a-8542-129ce7300646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf-gpu.1-15.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m94"
  },
  "kernelspec": {
   "display_name": "Custom [tf-gpu.1-15] (Local)",
   "language": "python",
   "name": "local-us-central1-docker.pkg.dev_lemmingsinthewind_workbench_tf-gpu.1-15_sha256_572a87b2ba89b08714325c28261c6917f5623fd6e31246cd07daa7200f9753e3__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
